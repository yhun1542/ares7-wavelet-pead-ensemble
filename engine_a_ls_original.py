#!/usr/bin/env python3
"""
ARES-7 Fast Vectorized Backtest Engine v80
- ë²¡í„°í™”ëœ ì—°ì‚°ìœ¼ë¡œ 100ë°° ì†ë„ í–¥ìƒ
- ì§„í–‰ë¥  ë¡œê¹… ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
- ì¤‘ë‹¨ í›„ ì¬ì‹œì‘ ê°€ëŠ¥
"""
import numpy as np
import pandas as pd
import pickle
import json
import logging
from datetime import datetime
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/tmp/backtest_v80.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FastBacktestV80:
    def __init__(self):
        # ê±°ë˜ë¹„ìš©
        self.COMMISSION_RATE = 0.0012  # 12bps
        self.SLIPPAGE_RATE = 0.0005    # 5bps
        
        # ë°±í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
        self.INITIAL_CAPITAL = 100000
        self.MAX_POSITIONS = 20
        self.MIN_HOLD_DAYS = 5
        self.MAX_HOLD_DAYS = 20
        
        # ===== v80 ë‹¨ì¼ ì—”ì§„ ë² ì´ìŠ¤ë¼ì¸ (ë³´ìˆ˜í˜• Top #1 ì¡°í•©) =====
        # Engine A: Momentum + Mean Reversion
        self.MOMENTUM_WEIGHT = 0.5
        self.MR_WEIGHT = 0.5
        self.SIGNAL_THRESHOLD = 0.035   # ìƒìœ„ ê°•í•œ ì‹œê·¸ë„ë§Œ ì§„ì…
        
        # ë¦¬ìŠ¤í¬ ê´€ë¦¬
        self.HARD_STOP = -0.08      # -8% ì†ì ˆ
        self.TRAILING_STOP = 0.0    # Trailing Stop ë¹„í™œì„±í™”
        self.PROFIT_TARGET = 0.15   # +15% ìµì ˆ
        
        # ìœ ë‹ˆë²„ìŠ¤ ì„¤ì •
        self.USE_ETF = False  # Phase 3-1: ETF ë¹„í™œì„±í™”, ì£¼ì‹ 100ê°œë§Œ ì‚¬ìš©
        
        # ===== ë©€í‹°ì—”ì§„ / ë©”íƒ€ ì˜µì…˜ì€ ì¡´ì¬í•˜ë”ë¼ë„ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë„ =====
        self.USE_MULTI_ENGINE = False  # â˜… ë‹¨ì¼ ì—”ì§„ ëª¨ë“œë¡œ ê³ ì •
        self.META_TARGET_P = 0.99      # R&Dìš©, í˜„ì¬ëŠ” ì‚¬ìš© ì•ˆ í•¨
        self.meta_threshold_ = None
        
        # ===== ë‹¨ì¼ ì—”ì§„ìš© THRESHOLD ìë™í™” ì˜µì…˜ =====
        # ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ì ˆëŒ€ê°’ ê¸°ì¤€ ìƒìœ„ p ë¹„ìœ¨ë§Œ ì§„ì… (ì˜ˆ: 0.98 = ìƒìœ„ 2%)
        self.SINGLE_TARGET_P = 0.98    # ìƒìœ„ 2% ì»· íƒ€ê¹ƒ (P=0.98 í™•ì •)
        self.single_threshold_ = None
        
        # ===== ì—”ì§„ ëª¨ë“œ í”Œë˜ê·¸ (A/B/C ì¤‘ ì„ íƒ) =====
        # "A" : ê¸°ì¡´ Momentum+MR ì—”ì§„
        # "B" : Short Reversal ì—”ì§„ (ë‹¨ê¸° ë¦¬ë²„ì„¤, R&Dìš©)
        # "C" : Low-Vol + Quality ì—”ì§„ (ì‹ ê·œ ì„¤ê³„, R&Dìš©)
        self.ENGINE_MODE = "A"  # Engine A: Momentum + Mean Reversion
        
        # ===== ë ˆì§ í•„í„° ì˜µì…˜ ì¶”ê°€ =====
        self.USE_REGIME_FILTER   = False    # ë ˆì§ í•„í„° ë¹„í™œì„±í™” (ìˆœìˆ˜ ì—”ì§„ ì„±ëŠ¥ í‰ê°€)
        self.REGIME_LOOKBACK_D   = 200      # ì¸ë±ìŠ¤ ì´ë™í‰ê·  ê¸°ê°„(ì¼)
        self.REGIME_MIN_PERIODS  = 120      # ìµœì†Œ ìœ íš¨ ê¸°ê°„
        self.REGIME_ON_VALUE     = 1        # Risk-ON í‘œì‹œê°’
        self.REGIME_OFF_VALUE    = 0        # Risk-OFF í‘œì‹œê°’
        
        # ë ˆì§ ê´€ë ¨ í†µê³„
        self.regime_days = {"on": 0, "off": 0}
        self.regime_blocked_entries = 0
        
        # í†µê³„
        self.stats = {
            'total_signals': 0,
            'blocked_reentry': 0,
            'stop_loss_hits': 0,
            'profit_target_hits': 0,
            'time_exits': 0
        }
        
    def apply_transaction_cost(self, value):
        """ê±°ë˜ë¹„ìš© ê³„ì‚°"""
        base_cost = abs(value) * (self.COMMISSION_RATE + self.SLIPPAGE_RATE)
        if abs(value) > 10000000:
            base_cost *= 1.2
        return base_cost
    
    def calculate_signals_vectorized(self, df):
        """
        ì‹œê·¸ë„ ê³„ì‚°:
        - ë‹¨ì¼ ì—”ì§„ ëª¨ë“œ: Engine A or B (ENGINE_MODEì— ë”°ë¼)
        - ë©€í‹°ì—”ì§„ ëª¨ë“œ: Engine A/B/C + meta_signal (R&Dìš©)
        """
        
        # 1) ë‹¨ì¼ ì—”ì§„ ëª¨ë“œ: ENGINE_MODEì— ë”°ë¼ A í˜¹ì€ Bë§Œ ì‚¬ìš©
        if not self.USE_MULTI_ENGINE:
            d = df.copy()
            d = d.sort_values(['symbol', 'timestamp']).reset_index(drop=True)
            g = d.groupby('symbol', group_keys=False)
            
            # --- Engine A: Momentum + MR (ê¸°ì¡´ ì—”ì§„) ---
            if self.ENGINE_MODE == "A":
                logger.info("ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚° ì¤‘... (Engine A: Momentum+MR)")
                
                ret20 = g['close'].pct_change(20)
                ret5  = g['close'].pct_change(5)
                
                mom_raw = ret20.shift(1)
                mr_raw  = -ret5.shift(1)
                
                # ê·¹ë‹¨ê°’ í´ë¦¬í•‘ (ê³¼ë„í•œ spike ë°©ì§€)
                mom_raw = mom_raw.clip(-0.15, 0.15)
                mr_raw  = mr_raw.clip(-0.15, 0.15)
                
                signal_A = self.MOMENTUM_WEIGHT * mom_raw + self.MR_WEIGHT * mr_raw
                
                d['signal'] = signal_A.fillna(0.0)
                
                logger.info(f"ë‹¨ì¼ ì—”ì§„ A ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ: {len(d)} rows (Momentum+MR)")
                return d
            
            # --- Engine B: Short Reversal (ë‹¨ê¸° ë¦¬ë²„ì„¤ ì „ìš©, R&Dìš©) ---
            elif self.ENGINE_MODE == "B":
                logger.info("ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚° ì¤‘... (Engine B: Short Reversal)")
                
                # 5ì¼ ìˆ˜ìµë¥ 
                ret5_long = g['close'].pct_change(5)
                
                # 60ì¼ ë¡¤ë§ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” (ë¦¬ë²„ì„¤ z-score)
                mean60 = ret5_long.rolling(60, min_periods=20).mean()
                std60  = ret5_long.rolling(60, min_periods=20).std(ddof=0)
                
                z_rev = -(ret5_long - mean60) / std60.replace(0, np.nan)
                
                # ë£©ì–´í—¤ë“œ ë°©ì§€: ì‹ í˜¸ëŠ” í•­ìƒ 1í‹±(1ì¼) ì§€ì—°
                signal_B = z_rev.shift(1)
                
                # ê·¹ë‹¨ê°’ í´ë¦¬í•‘ (ê³¼ë„í•œ spike ë°©ì§€)
                signal_B = signal_B.clip(-5.0, 5.0)
                
                d['signal'] = signal_B.fillna(0.0)
                
                logger.info(f"ë‹¨ì¼ ì—”ì§„ B ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ: {len(d)} rows (Short Reversal)")
                return d
            
            # --- Engine C v2: Ultra Simple Downside Low-Vol (ì‹ ê·œ ì„¤ê³„, R&Dìš©) ---
            elif self.ENGINE_MODE == "C":
                logger.info("ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚° ì¤‘... (Engine C v2: Ultra Simple Downside Low-Vol)")
                
                # 1) ì¼ê°„ ìˆ˜ìµë¥ 
                daily_ret = g['close'].pct_change()
                
                # 2) 60ì¼ downside volatility
                #    - ì–‘ìˆ˜ ìˆ˜ìµë¥ ì€ 0ìœ¼ë¡œ ë‚ ë¦¬ê³ , ìŒìˆ˜ êµ¬ê°„ì˜ stdë§Œ ë³¸ë‹¤.
                downside_ret = daily_ret.clip(upper=0)  # r>0 â†’ 0
                down_vol60 = downside_ret.rolling(60, min_periods=40).std(ddof=0)
                d['down_vol60'] = down_vol60
                
                # 3) ì¤‘ê¸° ëª¨ë©˜í…€/ì¥ê¸° ìˆ˜ìµë¥  (í•„í„°ìš©)
                ret120 = g['close'].pct_change(120)
                ret252 = g['close'].pct_change(252)
                d['ret120'] = ret120
                d['ret252'] = ret252
                
                # 4) ë‚ ì§œë³„ cross-section rank (0~1)
                def rank_pct(x):
                    return x.rank(pct=True)
                
                # ë‚®ì€ downside vol ì„ í˜¸ ì ìˆ˜ (0~1, 1ì´ ê°€ì¥ low-vol)
                d['lowvol_score'] = d.groupby('timestamp')['down_vol60'].transform(
                    lambda x: 1.0 - rank_pct(x)
                )
                
                # 5) ëª¨ë©˜í…€/í€´ì–¼ë¦¬í‹° í•„í„°
                # - 120ì¼ ìˆ˜ìµë¥  ì–‘ìˆ˜ì¸ ì¢…ëª©ë§Œ í†µê³¼
                d['mom_filter'] = (d['ret120'] > 0.0).astype(float)
                
                # - 252ì¼ ìˆ˜ìµë¥  10% ì´ìƒì¸ ì¢…ëª©ë§Œ quality pass
                d['qual_filter'] = (d['ret252'] > 0.10).astype(float)
                
                # 6) ìµœì¢… raw ì‹œê·¸ë„ = lowvol_score * mom_filter * qual_filter
                raw_signal = d['lowvol_score'] * d['mom_filter'] * d['qual_filter']
                
                # 7) ë£©ì–´í—¤ë“œ ë°©ì§€: 1í‹±(1ì¼) ì‹œí”„íŠ¸ í›„ ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ (ì¤‘ë¦½)
                signal_C = raw_signal.shift(1)
                d['signal'] = signal_C.fillna(0.0)
                
                logger.info(f"ë‹¨ì¼ ì—”ì§„ C v2 ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ: {len(d)} rows (Downside Low-Vol + Filters)")
                return d
            
            # --- ì •ì˜ë˜ì§€ ì•Šì€ ENGINE_MODEì¼ ë•Œ: ê¸°ë³¸ Aë¡œ fallback ---
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ENGINE_MODE={self.ENGINE_MODE}, Engine Aë¡œ fallback í•©ë‹ˆë‹¤.")
                
                ret20 = g['close'].pct_change(20)
                ret5  = g['close'].pct_change(5)
                
                mom_raw = ret20.shift(1)
                mr_raw  = -ret5.shift(1)
                
                mom_raw = mom_raw.clip(-0.15, 0.15)
                mr_raw  = mr_raw.clip(-0.15, 0.15)
                
                signal_A = self.MOMENTUM_WEIGHT * mom_raw + self.MR_WEIGHT * mr_raw
                
                d['signal'] = signal_A.fillna(0.0)
                
                logger.info(f"ë‹¨ì¼ ì—”ì§„ A(Fallback) ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ: {len(d)} rows")
                return d
        
        # 2) ë©€í‹°ì—”ì§„ ëª¨ë“œ: Engine A/B/C + meta_signal (R&D ì „ìš©)
        logger.info("ë©€í‹°ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚° ì¤‘... (R&D ëª¨ë“œ)")
        
        d = df.copy()
        # ì •ë ¬ ë° ê¸°ë³¸ ê·¸ë£¹
        d = d.sort_values(['symbol', 'timestamp']).reset_index(drop=True)
        g = d.groupby('symbol', group_keys=False)
        
        # -------------------------
        # Engine A: Momentum + MR
        # -------------------------
        # 20ì¼ ëª¨ë©˜í…€, 5ì¼ mean reversion (ë£©ì–´í—¤ë“œ ë°©ì§€ ìœ„í•´ shift(1))
        ret20 = g['close'].pct_change(20)
        ret5  = g['close'].pct_change(5)
        
        mom_raw = ret20.shift(1)            # ëª¨ë©˜í…€
        mr_raw  = -ret5.shift(1)            # mean reversion: ìµœê·¼ ë§ì´ ë¹ ì§„ ì•  ì„ í˜¸
        
        # ê·¹ë‹¨ê°’ í´ë¦¬í•‘ (ê³¼ë„í•œ spike ë°©ì§€)
        mom_raw = mom_raw.clip(-0.15, 0.15)
        mr_raw  = mr_raw.clip(-0.15, 0.15)
        
        signal_A_raw = self.MOMENTUM_WEIGHT * mom_raw + self.MR_WEIGHT * mr_raw
        
        # -------------------------
        # Engine B: Short Reversal
        # -------------------------
        # 5ì¼ ìˆ˜ìµë¥ ì„ 60ì¼ ë¡¤ë§ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” â†’ ê³¼ë„í•œ í•˜ë½ êµ¬ê°„ í¬ì°©
        ret5_long = g['close'].pct_change(5)
        mean60 = ret5_long.rolling(60, min_periods=20).mean()
        std60  = ret5_long.rolling(60, min_periods=20).std(ddof=0)
        
        z_rev = -(ret5_long - mean60) / std60.replace(0, np.nan)
        signal_B_raw = z_rev.shift(1)   # ë£©ì–´í—¤ë“œ ë°©ì§€
        
        # -------------------------
        # Engine C: Low-Vol + 60d Momentum
        # -------------------------
        # 60ì¼ ë³€ë™ì„± (ë‚®ì„ìˆ˜ë¡ ì„ í˜¸), 60ì¼ ëª¨ë©˜í…€ (ë†’ì„ìˆ˜ë¡ ì„ í˜¸)
        daily_ret = g['close'].pct_change()
        vol60 = daily_ret.rolling(60, min_periods=20).std(ddof=0)
        ret60 = g['close'].pct_change(60)
        
        d['vol60'] = vol60
        d['ret60'] = ret60
        
        # ë‚ ì§œë³„ cross-sectional rank ì‚¬ìš© (0~1)
        def rank_pct(x):
            return x.rank(pct=True)
        
        # ë‚®ì€ ë³€ë™ì„± ì„ í˜¸ â†’ rank ë†’ì„ìˆ˜ë¡ vol ë‚®ìŒ
        d['lowvol_score'] = d.groupby('timestamp')['vol60'].transform(
            lambda x: 1.0 - rank_pct(x)
        )
        d['mom60_score'] = d.groupby('timestamp')['ret60'].transform(rank_pct)
        
        signal_C_raw = (0.7 * d['lowvol_score'] + 0.3 * d['mom60_score']).shift(1)
        
        # -------------------------
        # cross-sectional z-score í‘œì¤€í™”
        # -------------------------
        d['signal_A_raw'] = signal_A_raw
        d['signal_B_raw'] = signal_B_raw
        d['signal_C_raw'] = signal_C_raw
        
        def zscore_cs(s):
            m = s.mean()
            v = s.std(ddof=0)
            if v is None or v == 0 or np.isnan(v):
                return pd.Series(0.0, index=s.index)
            return (s - m) / v
        
        d['zA'] = d.groupby('timestamp')['signal_A_raw'].transform(zscore_cs)
        d['zB'] = d.groupby('timestamp')['signal_B_raw'].transform(zscore_cs)
        d['zC'] = d.groupby('timestamp')['signal_C_raw'].transform(zscore_cs)
        
        # -------------------------
        # ë©”íƒ€ ì‹œê·¸ë„ ê°€ì¤‘í•©
        # -------------------------
        # ì´ˆê¸° ê°€ì¤‘ì¹˜ (ì¶”í›„ íŠœë‹ ê°€ëŠ¥): A 0.4 / B 0.3 / C 0.3
        wA, wB, wC = 0.4, 0.3, 0.3
        
        meta_signal = (
            wA * d['zA'].fillna(0.0) +
            wB * d['zB'].fillna(0.0) +
            wC * d['zC'].fillna(0.0)
        )
        
        # NaN â†’ 0 (ì¤‘ë¦½) ì²˜ë¦¬
        d['signal'] = meta_signal.fillna(0.0)
        
        logger.info(f"ë©€í‹°ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ: {len(d)} rows")
        logger.info(f"  Engine A (Momentum+MR), Engine B (Reversal), Engine C (LowVol+Mom60)")
        logger.info(f"  Meta Signal Weights: A={wA}, B={wB}, C={wC}")
        
        return d
    
    def run_backtest(self, data_path, checkpoint_file='/tmp/backtest_checkpoint.pkl'):
        """ë©”ì¸ ë°±í…ŒìŠ¤íŠ¸ ë¡œì§"""
        logger.info("="*70)
        logger.info("ARES-7 Fast Vectorized Backtest v80")
        logger.info("="*70)
        
        # ë°ì´í„° ë¡œë“œ
        logger.info(f"ë°ì´í„° ë¡œë“œ ì¤‘: {data_path}")
        with open(data_path, 'rb') as f:
            df = pickle.load(f)
        
        logger.info(f"ë°ì´í„°: {len(df)} rows, {df['symbol'].nunique()} symbols")
        
        # === ìœ ë‹ˆë²„ìŠ¤ êµ¬ì„± ===
        logger.info("\n" + "="*70)
        logger.info("ğŸŒ ìœ ë‹ˆë²„ìŠ¤ êµ¬ì„±")
        logger.info("="*70)
        
        if self.USE_ETF:
            # ETF í¬í•¨ ëª¨ë“œ
            ETF_WHITELIST = [
                'SPY', 'QQQ', 'IWM', 'XLK', 'XLF', 'XLV', 'XLE', 'XLY', 'XLP', 'XLU'
            ]
            
            symbols_in_data = df['symbol'].unique().tolist()
            etfs_in_data = [s for s in ETF_WHITELIST if s in symbols_in_data]
            
            is_etf = df['symbol'].isin(etfs_in_data)
            stock_df = df[~is_etf]
            etf_df = df[is_etf]
            
            top_stocks = stock_df.groupby('symbol')['volume'].sum().nlargest(80).index
            
            if len(etfs_in_data) > 0:
                top_etfs = etf_df.groupby('symbol')['volume'].sum().nlargest(20).index
            else:
                top_etfs = []
            
            universe = list(top_stocks) + list(top_etfs)
            logger.info(f"ì£¼ì‹: {len(top_stocks)}ê°œ, ETF: {len(top_etfs)}ê°œ, ì´ {len(universe)}ê°œ ì‹¬ë³¼")
        else:
            # ì£¼ì‹ 100ê°œë§Œ ì‚¬ìš© (Phase 3-1 ê¸°ë³¸ ëª¨ë“œ)
            top_stocks = df.groupby('symbol')['volume'].sum().nlargest(100).index
            universe = list(top_stocks)
            logger.info(f"ì£¼ì‹ ì „ìš© ëª¨ë“œ: {len(universe)}ê°œ ì‹¬ë³¼")
        
        df = df[df['symbol'].isin(universe)]
        logger.info("="*70 + "\n")
        
        # ì‹œê·¸ë„ ê³„ì‚°
        df = self.calculate_signals_vectorized(df)
        
        # === ë©€í‹°ì—”ì§„ meta_signal ë¶„í¬ ê¸°ë°˜ THRESHOLD ìë™ ì„¤ì • ===
        if self.USE_MULTI_ENGINE:
            abs_meta = df['signal'].abs()
            p = self.META_TARGET_P  # ì˜ˆ: 0.99 (ìƒìœ„ 1%)
            self.meta_threshold_ = float(abs_meta.quantile(p))
            
            logger.info("\n" + "="*70)
            logger.info("ğŸ¯ Meta Signal THRESHOLD ìë™ ì„¤ì •")
            logger.info("="*70)
            logger.info(f"Target Percentile: {p*100:.1f}% (ìƒìœ„ {100*(1-p):.2f}%)")
            logger.info(f"Auto Threshold: {self.meta_threshold_:.4f}")
            logger.info(f"\nMeta Signal ë¶„í¬:")
            logger.info(f"  Mean: {df['signal'].mean():.6f}")
            logger.info(f"  Std:  {df['signal'].std():.6f}")
            logger.info(f"  Min:  {df['signal'].min():.6f}")
            logger.info(f"  Max:  {df['signal'].max():.6f}")
            logger.info(f"\nì˜ˆìƒ ê±°ë˜ ìˆ˜: {(abs_meta > self.meta_threshold_).sum():,} rows")
            logger.info("="*70 + "\n")
        else:
            # ë‹¨ì¼ ì—”ì§„ ëª¨ë“œì—ì„œëŠ” meta_threshold ê³„ì‚° ì•ˆ í•¨
            self.meta_threshold_ = None
        
        # === ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ë¶„í¬ ê¸°ë°˜ THRESHOLD ìë™ ì„¤ì • ===
        if not self.USE_MULTI_ENGINE:
            if 'signal' not in df.columns:
                raise RuntimeError("calculate_signals í›„ df['signal'] ì»´ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ê³„ì‚°ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            abs_sig = df['signal'].abs().dropna()
            if len(abs_sig) == 0:
                self.single_threshold_ = None
                logger.warning("ê²½ê³ : ë‹¨ì¼ ì—”ì§„ ì‹œê·¸ë„ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. SIGNAL_THRESHOLD ê°’ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                p = self.SINGLE_TARGET_P   # ì˜ˆ: 0.98 (ìƒìœ„ 2% ì»·)
                self.single_threshold_ = float(abs_sig.quantile(p))
                
                logger.info("\n" + "="*70)
                logger.info("ğŸ¯ Single Engine Signal THRESHOLD ìë™ ì„¤ì •")
                logger.info("="*70)
                logger.info(f"Target Percentile: {p*100:.1f}% (ìƒìœ„ {100*(1-p):.2f}%)")
                logger.info(f"Auto Threshold: {self.single_threshold_:.4f}")
                logger.info(f"\nSingle Signal ë¶„í¬:")
                logger.info(f"  Mean: {df['signal'].mean():.6f}")
                logger.info(f"  Std:  {df['signal'].std():.6f}")
                logger.info(f"  Min:  {df['signal'].min():.6f}")
                logger.info(f"  Max:  {df['signal'].max():.6f}")
                logger.info(f"\nì˜ˆìƒ ê±°ë˜ ìˆ˜: {(abs_sig > self.single_threshold_).sum():,} rows")
                logger.info("="*70 + "\n")
        else:
            self.single_threshold_ = None
        
        # === ë ˆì§ ê³„ì‚°: ìœ ë‹ˆë²„ìŠ¤ í‰ê·  ê°€ê²© ê¸°ë°˜ ì¸ë±ìŠ¤ + 200ì¼ MA ===
        if self.USE_REGIME_FILTER:
            logger.info("\n" + "="*70)
            logger.info("ğŸš¦ ë ˆì§ í•„í„° ê³„ì‚° ì¤‘...")
            logger.info("="*70)
            
            # df: ['timestamp','symbol','close','signal', ...] ê°€ì •
            df = df.sort_values(['timestamp', 'symbol']).reset_index(drop=True)
            
            # 1) ë‚ ì§œë³„ ìœ ë‹ˆë²„ìŠ¤ í‰ê·  ì¢…ê°€ë¡œ "ì‹œì¥ ì¸ë±ìŠ¤" ìƒì„±
            mkt = (
                df.groupby('timestamp')['close']
                  .mean()
                  .rename('mkt_index')
                  .to_frame()
                  .sort_index()
            )
            
            # 2) 200ì¼ ë‹¨ìˆœ ì´ë™í‰ê·  ê³„ì‚°
            lookback = self.REGIME_LOOKBACK_D
            minp     = self.REGIME_MIN_PERIODS
            mkt['mkt_ma'] = mkt['mkt_index'].rolling(lookback, min_periods=minp).mean()
            
            # 3) ë ˆì§ í”Œë˜ê·¸: ì¸ë±ìŠ¤ > MA ì´ë©´ Risk-ON(1), ì•„ë‹ˆë©´ Risk-OFF(0)
            mkt['regime_flag'] = np.where(
                mkt['mkt_index'] > mkt['mkt_ma'],
                self.REGIME_ON_VALUE,
                self.REGIME_OFF_VALUE
            )
            
            # 4) dfì— ë ˆì§ ì •ë³´ merge
            df = df.merge(
                mkt[['regime_flag']],
                left_on='timestamp',
                right_index=True,
                how='left'
            )
            
            # NaN ë ˆì§(ì´ˆê¸° êµ¬ê°„)ëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ Risk-OFF ì²˜ë¦¬
            df['regime_flag'] = df['regime_flag'].fillna(self.REGIME_OFF_VALUE).astype(int)
            
            # ë ˆì§ ì¼ìˆ˜ ì¹´ìš´íŒ… (ì •ë³´ìš©)
            n_on  = int((mkt['regime_flag'] == self.REGIME_ON_VALUE).sum())
            n_off = int((mkt['regime_flag'] == self.REGIME_OFF_VALUE).sum())
            self.regime_days['on']  = n_on
            self.regime_days['off'] = n_off
            
            logger.info(f"ë ˆì§ ê³„ì‚° ì™„ë£Œ: Risk-ON={n_on}ì¼ ({n_on/(n_on+n_off)*100:.1f}%), Risk-OFF={n_off}ì¼ ({n_off/(n_on+n_off)*100:.1f}%)")
            logger.info("="*70 + "\n")
        else:
            # ë ˆì§ í•„í„° ë¯¸ì‚¬ìš© ì‹œ ë”ë¯¸ ì»´ëŸ¼ ì¶”ê°€
            df['regime_flag'] = self.REGIME_ON_VALUE
            logger.info("ë ˆì§ í•„í„° ë¹„í™œì„±í™” (Risk-ON ê³ ì •)\n")
        
        # === ì‹œê·¸ë„ ë¶„í¬ ì§„ë‹¨ ===
        logger.info("\n" + "="*70)
        logger.info("ğŸ” ì‹œê·¸ë„ ë¶„í¬ ì§„ë‹¨")
        logger.info("="*70)
        
        sig = df['signal'].dropna()
        abs_sig = sig.abs()
        
        logger.info("\nê¸°ë³¸ í†µê³„:")
        logger.info(f"  Mean: {sig.mean():.6f}")
        logger.info(f"  Std:  {sig.std():.6f}")
        logger.info(f"  Min:  {sig.min():.6f}")
        logger.info(f"  Max:  {sig.max():.6f}")
        
        logger.info("\n|signal| > threshold ë¹„ìœ¨:")
        for th in [0.05, 0.1, 0.15, 0.2, 0.3]:
            ratio = (abs_sig > th).mean()
            count = (abs_sig > th).sum()
            logger.info(f"  |signal| > {th:.2f}: {ratio*100:6.3f}% ({count:,} rows)")
        
        logger.info("\nQuantiles of |signal|:")
        for q in [0.5, 0.8, 0.9, 0.95, 0.99]:
            val = abs_sig.quantile(q)
            logger.info(f"  {q*100:.0f}%: {val:.6f}")
        
        logger.info("="*70 + "\n")
        
        # ë‚ ì§œë³„ ì¸ë±ìŠ¤ ìƒì„± (ë²¡í„°í™” ìµœì í™”)
        logger.info("ë‚ ì§œë³„ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        df['date_idx'] = pd.factorize(df['timestamp'])[0]
        dates = sorted(df['timestamp'].unique())
        
        # ì¢…ëª©ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (ë¹ ë¥¸ ì ‘ê·¼)
        logger.info("ì¢…ëª©ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„± ì¤‘...")
        symbol_data = {sym: group for sym, group in df.groupby('symbol')}
        
        # ì´ˆê¸°í™”
        cash = self.INITIAL_CAPITAL
        positions = {}
        trades = []
        daily_equity = {}
        
        total_days = len(dates)
        logger.info(f"ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘: {total_days} days")
        
        # ì§„í–‰ë¥  ì²´í¬í¬ì¸íŠ¸
        checkpoint_interval = 500
        progress_interval = 100
        
        for day_idx, date in enumerate(dates):
            # ì§„í–‰ë¥  ì¶œë ¥
            if (day_idx + 1) % progress_interval == 0:
                progress_pct = (day_idx + 1) / total_days * 100
                logger.info(f"ì§„í–‰ë¥ : {day_idx+1}/{total_days} ({progress_pct:.1f}%) - "
                          f"Positions: {len(positions)}, Trades: {len(trades)}, "
                          f"Cash: ${cash:,.0f}")
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if (day_idx + 1) % checkpoint_interval == 0:
                checkpoint = {
                    'day_idx': day_idx,
                    'cash': cash,
                    'positions': positions.copy(),
                    'trades': trades.copy(),
                    'daily_equity': daily_equity.copy(),
                    'stats': self.stats.copy()
                }
                with open(checkpoint_file, 'wb') as f:
                    pickle.dump(checkpoint, f)
                logger.info(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_file}")
            
            # í˜„ì¬ ë‚ ì§œ ë°ì´í„°
            day_data = df[df['timestamp'] == date]
            
            # === 1. ê¸°ì¡´ í¬ì§€ì…˜ ì²´í¬ ===
            for symbol in list(positions.keys()):
                pos = positions[symbol]
                
                # í˜„ì¬ ê°€ê²©
                current = day_data[day_data['symbol'] == symbol]
                if current.empty:
                    continue
                
                current_price = current['close'].iloc[0]
                pnl_pct = (current_price - pos['entry_price']) / pos['entry_price']
                hold_days = (date - pos['entry_date']).days
                
                # High Water Mark ê°±ì‹ 
                if 'high_water_mark' not in pos:
                    pos['high_water_mark'] = current_price
                else:
                    pos['high_water_mark'] = max(pos['high_water_mark'], current_price)
                
                exit_reason = None
                
                # MIN_HOLD_DAYS ì´ì „ì—ëŠ” HARD_STOPë§Œ í—ˆìš©
                if hold_days < self.MIN_HOLD_DAYS:
                    if pnl_pct <= self.HARD_STOP:
                        exit_reason = 'STOP_LOSS'
                        self.stats['stop_loss_hits'] += 1
                else:
                    # ì†ì ˆ
                    if pnl_pct <= self.HARD_STOP:
                        exit_reason = 'STOP_LOSS'
                        self.stats['stop_loss_hits'] += 1
                    
                    # Trailing Stop (High Water Mark ê¸°ì¤€)
                    elif self.TRAILING_STOP > 0 and (current_price - pos['high_water_mark']) / pos['high_water_mark'] <= -self.TRAILING_STOP:
                        exit_reason = 'TRAILING_STOP'
                        self.stats['trailing_stop_hits'] = self.stats.get('trailing_stop_hits', 0) + 1
                    
                    # ìµì ˆ
                    elif pnl_pct >= self.PROFIT_TARGET:
                        exit_reason = 'PROFIT_TARGET'
                        self.stats['profit_target_hits'] += 1
                    
                    # ì‹œê°„ ì¢…ë£Œ
                    elif hold_days >= self.MAX_HOLD_DAYS:
                        exit_reason = 'TIME_EXIT'
                        self.stats['time_exits'] += 1
                
                # ì²­ì‚°
                if exit_reason:
                    proceeds = pos['shares'] * current_price
                    exit_cost = self.apply_transaction_cost(proceeds)
                    net_proceeds = proceeds - exit_cost
                    
                    cash += net_proceeds
                    
                    trades.append({
                        'symbol': symbol,
                        'entry_date': pos['entry_date'],
                        'exit_date': date,
                        'entry_price': pos['entry_price'],
                        'exit_price': current_price,
                        'shares': pos['shares'],
                        'net_pnl': net_proceeds - pos['cost_basis'],
                        'exit_reason': exit_reason
                    })
                    
                    del positions[symbol]
            
            # === 2. ì‹ ê·œ ì§„ì… ===
            # ë‹¹ì¼ ë ˆì§ ê°’ (0 or 1)
            if self.USE_REGIME_FILTER:
                # day_data ì „ì²´ê°€ ë™ì¼í•œ regime_flagë¥¼ ê°€ì§ˆ ê²ƒì´ë¯€ë¡œ ì²« ê°’ ì‚¬ìš©
                regime_today = int(day_data['regime_flag'].iloc[0])
            else:
                regime_today = self.REGIME_ON_VALUE  # í•„í„° ë¯¸ì‚¬ìš©ì‹œ í•­ìƒ ON ì·¨ê¸‰
            
            # Risk-OFF ì¼ ë•Œ ì‹ ê·œ ì§„ì… ê¸ˆì§€
            if self.USE_REGIME_FILTER and regime_today == self.REGIME_OFF_VALUE:
                # ì´ ë‚ ì€ Risk-OFF â†’ ì‹ ê·œ ì§„ì… ê¸ˆì§€
                # (ë¦¬ìŠ¤í¬ ê´€ë¦¬ëŠ” ì´ë¯¸ ìœ„ ë‹¨ê³„ì—ì„œ ì²˜ë¦¬)
                # ì°¨ë‹¨ëœ ì§„ì… í›„ë³´ ìˆ˜ ì¹´ìš´íŒ…
                potential_entries = day_data[day_data['signal'] > self.SIGNAL_THRESHOLD]
                self.regime_blocked_entries += len(potential_entries)
                continue
            
            # ì—”íŠ¸ë¦¬ìš© threshold ê²°ì •
            threshold = self.SIGNAL_THRESHOLD
            
            # 1) ë‹¨ì¼ ì—”ì§„ ëª¨ë“œë©´ single_threshold_ ìš°ì„ 
            if (not self.USE_MULTI_ENGINE) and (self.single_threshold_ is not None):
                threshold = self.single_threshold_
            
            # 2) ë©€í‹°ì—”ì§„ ëª¨ë“œë©´ meta_threshold_ (ìˆì„ ê²½ìš°)
            elif self.USE_MULTI_ENGINE and (self.meta_threshold_ is not None):
                threshold = self.meta_threshold_
            
            strong_signals = day_data[day_data['signal'] > threshold]
            strong_signals = strong_signals.nlargest(
                min(self.MAX_POSITIONS - len(positions), 5),
                'signal'
            )
            
            for _, row in strong_signals.iterrows():
                symbol = row['symbol']
                
                # ì¬ì§„ì… ê°€ë“œ
                if symbol in positions:
                    self.stats['blocked_reentry'] += 1
                    continue
                
                # í¬ì§€ì…˜ í¬ê¸°
                position_size = min(
                    cash * 0.05,
                    cash / max(1, self.MAX_POSITIONS - len(positions))
                )
                
                if position_size < 1000:
                    continue
                
                entry_price = row['close']
                entry_cost = self.apply_transaction_cost(position_size)
                shares = position_size / entry_price
                total_cost = position_size + entry_cost
                
                if cash >= total_cost:
                    positions[symbol] = {
                        'entry_date': date,
                        'entry_price': entry_price,
                        'shares': shares,
                        'cost_basis': total_cost
                    }
                    
                    cash -= total_cost
                    self.stats['total_signals'] += 1
            
            # === 3. ì¼ë³„ ì—ì¿¼í‹° ê¸°ë¡ ===
            portfolio_value = cash
            for symbol, pos in positions.items():
                current = day_data[day_data['symbol'] == symbol]
                if not current.empty:
                    portfolio_value += current['close'].iloc[0] * pos['shares']
            
            daily_equity[date] = portfolio_value
        
        logger.info("ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì„±ê³¼ ê³„ì‚° ì¤‘...")
        
        # === 4. ì„±ê³¼ ê³„ì‚° ===
        equity_df = pd.DataFrame(list(daily_equity.items()), 
                                columns=['date', 'equity'])
        equity_df['date'] = pd.to_datetime(equity_df['date'])
        equity_df = equity_df.set_index('date').sort_index()
        
        # ì¼ë³„ ë¦¬ìƒ˜í”Œë§
        daily = equity_df.resample('B').last().ffill()
        daily_returns = daily['equity'].pct_change().dropna()
        
        # ìƒ¤í”„ ë¹„ìœ¨
        if len(daily_returns) > 0:
            sharpe = (daily_returns.mean() / daily_returns.std() * np.sqrt(252)) \
                    if daily_returns.std() > 0 else 0
            
            # ìµœëŒ€ ë‚™í­
            cummax = daily['equity'].cummax()
            drawdown = (daily['equity'] - cummax) / cummax
            max_dd = drawdown.min()
            
            # ì—°í™˜ì‚° ìˆ˜ìµë¥ 
            total_return = (daily['equity'].iloc[-1] / self.INITIAL_CAPITAL) - 1
            days = len(daily)
            annual_return = (1 + total_return) ** (252 / days) - 1 if days > 0 else 0
            
            # ì—°í™˜ì‚° ë³€ë™ì„±
            annual_vol = daily_returns.std() * np.sqrt(252)
        else:
            sharpe = max_dd = annual_return = annual_vol = 0
        
        # Profit Factor
        trades_df = pd.DataFrame(trades)
        if len(trades_df) > 0:
            wins = trades_df[trades_df['net_pnl'] > 0]['net_pnl'].sum()
            losses = abs(trades_df[trades_df['net_pnl'] < 0]['net_pnl'].sum())
            profit_factor = wins / losses if losses > 0 else 999
            win_rate = len(trades_df[trades_df['net_pnl'] > 0]) / len(trades_df)
        else:
            profit_factor = win_rate = 0
        
        # === 5. ê²°ê³¼ ì¶œë ¥ ===
        logger.info("\n" + "="*70)
        logger.info("ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ (Fast v80)")
        logger.info("="*70)
        logger.info(f"Sharpe Ratio:      {sharpe:.3f}")
        logger.info(f"Annual Return:     {annual_return:.1%}")
        logger.info(f"Annual Volatility: {annual_vol:.1%}")
        logger.info(f"Max Drawdown:      {max_dd:.1%}")
        logger.info(f"Profit Factor:     {profit_factor:.2f}")
        logger.info(f"Win Rate:          {win_rate:.1%}")
        logger.info(f"Total Trades:      {len(trades_df)}")
        
        logger.info("\nğŸ“ˆ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í†µê³„")
        logger.info(f"ì´ ì‹œê·¸ë„:         {self.stats['total_signals']}")
        logger.info(f"ì¬ì§„ì… ì°¨ë‹¨:       {self.stats['blocked_reentry']}")
        logger.info(f"ì†ì ˆ ë°œìƒ:         {self.stats['stop_loss_hits']}")
        logger.info(f"ìµì ˆ ë°œìƒ:         {self.stats['profit_target_hits']}")
        logger.info(f"ì‹œê°„ ì²­ì‚°:         {self.stats['time_exits']}")
        
        # ë ˆì§ í†µê³„ ì¶œë ¥
        if self.USE_REGIME_FILTER:
            logger.info("\nğŸš¦ ë ˆì§ í•„í„° í†µê³„")
            logger.info(f"Risk-ON ì¼ìˆ˜:  {self.regime_days['on']}")
            logger.info(f"Risk-OFF ì¼ìˆ˜: {self.regime_days['off']}")
            logger.info(f"ë ˆì§ìœ¼ë¡œ ì‹ ê·œ ì§„ì… ì°¨ë‹¨: {self.regime_blocked_entries}")
        
        # daily_returnsë¥¼ JSONì— ì €ì¥í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        if len(daily_returns) > 0:
            daily_ret_list = [
                {"date": idx.strftime("%Y-%m-%d"), "ret": float(val)}
                for idx, val in daily_returns.items()
            ]
        else:
            daily_ret_list = []
        
        # ê²°ê³¼ ì €ì¥
        output = {
            'sharpe': sharpe,
            'annual_return': annual_return,
            'annual_volatility': annual_vol,
            'max_drawdown': max_dd,
            'profit_factor': profit_factor,
            'win_rate': win_rate,
            'total_trades': len(trades_df),
            'stats': self.stats,
            'regime_stats': {
                'use_regime_filter': self.USE_REGIME_FILTER,
                'regime_days': self.regime_days,
                'regime_blocked_entries': self.regime_blocked_entries
            },
            'daily_returns': daily_ret_list,   # â˜… ì¶”ê°€
            'trades': trades_df.to_dict('records') if len(trades_df) > 0 else []
        }
        
        # ENGINE_MODEì— ë”°ë¼ ì €ì¥ ê²½ë¡œ ë™ì  ì„¤ì •
        if self.ENGINE_MODE == "A":
            out_path = "/tmp/engine_a_single_results.json"
        elif self.ENGINE_MODE == "B":
            out_path = "/tmp/engine_b_single_results.json"
        elif self.ENGINE_MODE == "C":
            out_path = "/tmp/engine_c_single_results.json"
        else:
            out_path = "/tmp/ares7_v80_results_with_etf.json"  # fallback
        
        with open(out_path, 'w') as f:
            json.dump(output, f, indent=2, default=str)
        
        logger.info(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {out_path}")
        logger.info("="*70)
        
        return output

if __name__ == "__main__":
    import sys
    
    data_path = '/tmp/ares7_training_data.pkl'
    if len(sys.argv) > 1:
        data_path = sys.argv[1]
    
    bt = FastBacktestV80()
    result = bt.run_backtest(data_path)
    
    logger.info(f"\nâœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ! Sharpe: {result['sharpe']:.3f}")
